# -*- coding: utf-8 -*-
"""Text Classification_PyToch_BERT_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1szdaMTRTD2ubEPw9K9qf5lN9iP6Y_oAL
"""

!pip install transformers --quiet
!pip install opendatasets --quiet

import opendatasets as od
od.download("https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection")

import torch
import torch.nn as nn
from torch.optim import Adam
from transformers import AutoTokenizer, AutoModel
from torch.utils.data import DataLoader,Dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

device ='cuda' if torch.cuda.is_available() else "cpu"
print("Available Device: ",device)

data_df=pd.read_json('/content/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json', lines=True)
data_df.dropna(inplace=True)
data_df.drop_duplicates(inplace=True)
data_df.drop(["article_link"], inplace=True, axis=1)
data_df.head()

X_train, X_test, y_train,y_test=train_test_split(np.array(data_df["headline"]), np.array(data_df["is_sarcastic"]), test_size=0.3)
X_val, X_test,y_val,y_test=train_test_split(X_test, y_test, test_size=0.5)

print("Training Size: ", X_train.shape[0], " rows which is: ", round(X_train.shape[0]/data_df.shape[0],4)*100,"%")
print("Validation Size: ", X_val.shape[0], " rows which is: ", round(X_val.shape[0]/data_df.shape[0],4)*100,"%")
print("Testing Size: ", X_test.shape[0], "  rows which is: ", round(X_test.shape[0]/data_df.shape[0],4)*100,"%")

tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-uncased")
bert_model = AutoModel.from_pretrained("google-bert/bert-base-uncased")

class dataset(Dataset):
  def __init__(self,X,Y):
    self.X=[tokenizer(x,max_length=100,truncation=True, padding ="max_length",return_tensors='pt').to(device)
    for x in X]
    self.Y=torch.tensor(Y,dtype=torch.float32).to(device)

  def __len__(self):
    return len(self.X)
  def __getitem__(self,indx):
    return self.X[indx],self.Y[indx]

training_data=dataset(X_train, y_train)
validation_data=dataset(X_val, y_val)
testing_data=dataset(X_test, y_test)

BATCH_SIZE=32
EPOCHS=10
LR=1e-4

train_dataloader=DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)
validation_dataloader=DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True)
test_dataloader=DataLoader(testing_data, batch_size=BATCH_SIZE, shuffle=True)

class MyModel(nn.Module):
  def __init__(self,bert):
    super(MyModel, self).__init__()

    self.bert=bert
    self.dropout=nn.Dropout(0.25)
    self.linear1=nn.Linear(768,384)
    self.linear2=nn.Linear(384,1)
    self.sigmoid=nn.Sigmoid()

  def forward(self,input_ids,attention_mask):
    pooled_output=self.bert(input_ids, attention_mask,return_dict=False)[0][:,0]
    output=self.linear1(pooled_output)
    output=self.dropout(output)
    output=self.linear2(output)
    output=self.sigmoid(output)
    return output

for param in bert_model.parameters():
  param.requires_grad=False
model=MyModel(bert_model).to(device)

model

criterion=nn.BCELoss()
optimizer=Adam(model.parameters(),lr=LR)

total_loss_train_plot=[]
total_loss_validation_plot=[]
total_acc_train_plot=[]
total_acc_validation_plot=[]

for epoch in range(EPOCHS):
  total_acc_train=0
  total_loss_train=0
  total_acc_val=0
  total_loss_val=0
  for indx,data in enumerate(train_dataloader):
    inputs,labels=data
    inputs = {k: v.to(device) for k, v in inputs.items()}
    labels = labels.to(device)


    prediction=model(inputs["input_ids"].squeeze(1),inputs["attention_mask"].squeeze(1)).squeeze(1)
    batch_loss=criterion(prediction,labels)
    total_loss_train+=batch_loss.item()

    acc=(prediction.round()==labels).sum().item()

    total_acc_train+=acc
    batch_loss.backward()
    optimizer.step()
    optimizer.zero_grad()

  with torch.no_grad():
    for indx,data in enumerate(validation_dataloader):
      inputs,labels=data
      inputs.to(device)
      labels.to(device)

      prediction=model(inputs["input_ids"].squeeze(1),inputs["attention_mask"].squeeze(1)).squeeze(1)
      batch_loss=criterion(prediction,labels)
      total_loss_val+=batch_loss.item()

      acc=(prediction.round()==labels).sum().item()

      total_acc_val+=acc

  total_loss_train_plot.append(round(total_loss_train/1000,4))
  total_loss_validation_plot.append(round(total_loss_val/1000,4))
  total_acc_train_plot.append(round(total_acc_train/training_data.__len__() * 100,4))
  total_acc_validation_plot.append(round(total_acc_val/validation_data.__len__()*100,4))
  print(f"""
     Epoch No. {epoch+1} Train loss: {round(total_loss_train/1000,4)} Train Accuracy: {round(total_acc_train/training_data.__len__() * 100,4)}
      Validation loss: {round(total_loss_val/1000,4)} Validation Accuracy: {round(total_acc_val/validation_data.__len__()*100,4)}
     """)

with torch.no_grad():
  total_loss_test=0
  total_acc_test=0

  for indx,data in enumerate(test_dataloader):
    inputs,labels=data
    inputs.to(device)
    labels.to(device)

    prediction=model(inputs["input_ids"].squeeze(1),inputs["attention_mask"].squeeze(1)).squeeze(1)
    batch_loss =criterion (prediction,labels)
    total_loss_test+=batch_loss.item()

    acc=(prediction.round()==labels).sum().item()
    total_acc_test+=acc

print(f"Accuracy Score on testing Data is: {round(total_acc_test/len(testing_data)*100,4)}")

fig, axs=plt.subplots(nrows=1,ncols=2,figsize=(15,5))

axs[0].plot(total_loss_train_plot,label='Training Loss')
axs[0].plot(total_loss_validation_plot,label='Validation Loss')
axs[0].set_title('Training and Validation Loss over Epochs')
axs[0].set_xlabel('Epochs')
axs[0].set_ylabel('Loss')
axs[0].set_ylim([0,1])
axs[0].legend()

axs[1].plot(total_acc_train_plot,label='Training Accuracy')
axs[1].plot(total_acc_validation_plot,label='Validation Accuracy')
axs[1].set_title('Training and Validation Accuracy over Epochs')
axs[1].set_xlabel('Epochs')
axs[1].set_ylabel(' Accuracy')
axs[1].set_ylim([0,100])
axs[1].legend()